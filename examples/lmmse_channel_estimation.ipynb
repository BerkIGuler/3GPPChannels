{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "3ba305f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import yaml\n",
        "import pprint\n",
        "from pathlib import Path\n",
        "import random\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "6e241067",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_channel_power(data):\n",
        "    return np.mean(np.abs(data)**2)\n",
        "\n",
        "def compute_autocorrelation(hp_ls):\n",
        "    if hp_ls.ndim == 2:\n",
        "        hp_ls = hp_ls.unsqueeze(0)  # add batch dimension\n",
        "    assert hp_ls.ndim == 3\n",
        "\n",
        "    batch_size = hp_ls.shape[0]\n",
        "\n",
        "    hp_ls = hp_ls.reshape(batch_size, -1)  # row-major flatten\n",
        "\n",
        "    hp_ls_autocorr = np.conj(hp_ls.T) @ hp_ls\n",
        "    return hp_ls_autocorr / batch_size\n",
        "\n",
        "def lmmse_interpolation(hp_ls, SNR, pilot_autocorr, channel_pilot_corr):\n",
        "    raise NotImplementedError(\"LMMSE interpolation is not implemented yet\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "716c2716",
      "metadata": {},
      "outputs": [],
      "source": [
        "class TDLDataset(Dataset):\n",
        "    def __init__(\n",
        "        self, data_path, *, file_size, normalization_stats=None,return_pilots_only=True, num_subcarriers=120,\n",
        "        num_symbols=14, SNRs=[0, 5, 10, 15, 20, 25, 30],\n",
        "        pilot_symbols=[2, 11], pilot_every_n=2):\n",
        "        \"\"\"\n",
        "        This class loads the data from the folder and returns a dataset of channels.\n",
        "\n",
        "        data_path: path to the folder containing the data\n",
        "        file_size: number of channels per file\n",
        "        return_pilots_only: if True, only the LS channel estimate at pilots are returned\n",
        "            if False, the LS channel estimate is returned as a sparse channel matrix with non-zero \n",
        "            values only at the pilot subcarriers and time instants.\n",
        "        num_subcarriers: number of subcarriers\n",
        "        num_symbols: number of OFDM symbols\n",
        "\n",
        "        SNRs: list of SNR values to randomly sample from when return LS estimates.\n",
        "            AWGN is added to simulate LS estimatation error\n",
        "        pilot_symbols: list of OFDM symbol indices where pilots are placed\n",
        "        pilot_every_n: number of subcarriers between pilot subcarriers\n",
        "        \"\"\"\n",
        "        \n",
        "        self.file_size = int(file_size)\n",
        "        self.normalization_stats = normalization_stats\n",
        "        self.return_pilots_only = return_pilots_only\n",
        "        self.num_subcarriers = num_subcarriers\n",
        "        self.num_symbols = num_symbols\n",
        "        self.SNRs = SNRs\n",
        "        self.pilot_symbols = pilot_symbols\n",
        "        self.pilot_every_n = pilot_every_n\n",
        "\n",
        "        self.file_list = list(Path(data_path).glob(\"*.npy\"))\n",
        "        self.stats = self._get_stats_per_file(self.file_list)\n",
        "        self.data = self._load_data_from_folder(self.file_list, self.normalization_stats)\n",
        "        self.pilot_mask = self._get_pilot_mask()\n",
        "\n",
        "        self.num_pilot_symbols = len(self.pilot_symbols)\n",
        "        self.num_pilot_subcarriers = int(self.pilot_mask.sum()) // self.num_pilot_symbols\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list) * self.file_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_idx = idx // self.file_size\n",
        "        sample_idx = idx % self.file_size\n",
        "        file_path = self.file_list[file_idx]\n",
        "        channels = self.data[file_path]\n",
        "        channel = channels[sample_idx].squeeze().T\n",
        "\n",
        "        SNR = random.choice(self.SNRs)\n",
        "        LS_channel_at_pilots = self._get_LS_estimate_at_pilots(channel, SNR)\n",
        "        stats = self.stats[file_path]\n",
        "        stats[\"SNR\"] = SNR\n",
        "\n",
        "        LS_channel_at_pilots_torch = torch.from_numpy(LS_channel_at_pilots).to(torch.complex64)\n",
        "        channel_torch = torch.from_numpy(channel).to(torch.complex64)\n",
        "        return LS_channel_at_pilots_torch, channel_torch, stats\n",
        "    \n",
        "    @staticmethod\n",
        "    def _load_data_from_folder(file_list, normalization_stats=None):\n",
        "        data = {}\n",
        "        for file_path in file_list:\n",
        "            file_data = np.load(file_path)\n",
        "            if normalization_stats is not None:\n",
        "                normalized_real = (file_data.real - normalization_stats[\"real_mean\"]) / normalization_stats[\"real_std\"]\n",
        "                normalized_imag = (file_data.imag - normalization_stats[\"imag_mean\"]) / normalization_stats[\"imag_std\"]\n",
        "                file_data = normalized_real + 1j * normalized_imag\n",
        "            data[file_path] = file_data\n",
        "        return data\n",
        "\n",
        "    @staticmethod\n",
        "    def _get_stats_per_file(file_list):\n",
        "        stats = {}\n",
        "\n",
        "        for file_path in file_list:\n",
        "            file_name = str(file_path.stem)\n",
        "            file_parts = file_name.split(\"_\")\n",
        "\n",
        "            if file_parts[0] == \"delay\":\n",
        "                delay_spread = int(file_parts[2])  # [delay, spread, y, doppler, x]\n",
        "                doppler_shift = int(file_parts[-1])\n",
        "            elif file_parts[0] == \"doppler\":\n",
        "                doppler_shift = int(file_parts[1])  # [doppler, x, delay, spread, y]\n",
        "                delay_spread = int(file_parts[-1])\n",
        "            else:\n",
        "                raise ValueError(f\"File {file_name} has unexpected format\")\n",
        "            \n",
        "            if file_path not in stats:\n",
        "                stats[file_path] = {\"doppler_shift\": doppler_shift, \"delay_spread\": delay_spread}\n",
        "            else:\n",
        "                raise ValueError(f\"File {file_path} already in stats, but should not be\")\n",
        "            \n",
        "        return stats\n",
        "    \n",
        "    def _get_LS_estimate_at_pilots(self, channel_matrix, SNR):\n",
        "        # unit symbol power and unit channel power --> rx noise var = LS error var\n",
        "        noise_std = np.sqrt(1 / (10**(SNR / 10)))\n",
        "        noise_real_imag = noise_std / np.sqrt(2)\n",
        "\n",
        "        if self.return_pilots_only:\n",
        "            pilot_mask_bool = self.pilot_mask.astype(bool)\n",
        "            channel_at_pilots = channel_matrix[pilot_mask_bool]\n",
        "            channel_at_pilots = channel_at_pilots.reshape(self.num_pilot_subcarriers, self.num_pilot_symbols)\n",
        "            noise_real = noise_real_imag * np.random.randn(self.num_pilot_subcarriers, self.num_pilot_symbols)\n",
        "            noise_imag = noise_real_imag * np.random.randn(self.num_pilot_subcarriers, self.num_pilot_symbols)\n",
        "            noise = noise_real + 1j * noise_imag\n",
        "        else:\n",
        "            channel_at_pilots = self.pilot_mask * channel_matrix\n",
        "            noise_real = noise_real_imag * np.random.randn(self.num_subcarriers, self.num_symbols)\n",
        "            noise_imag = noise_real_imag * np.random.randn(self.num_subcarriers, self.num_symbols)\n",
        "            noise = noise_real + 1j * noise_imag\n",
        "            noise = noise * self.pilot_mask\n",
        "        \n",
        "        channel_at_pilots_LS = channel_at_pilots + noise\n",
        "            \n",
        "        return channel_at_pilots_LS\n",
        "\n",
        "    def _get_pilot_mask(self):\n",
        "        pilot_mask = np.zeros((self.num_subcarriers, self.num_symbols))\n",
        "        pilot_mask_subcarrier_indices = np.arange(0, self.num_subcarriers, self.pilot_every_n)\n",
        "        pilot_mask[np.ix_(pilot_mask_subcarrier_indices, self.pilot_symbols)] = 1\n",
        "        return pilot_mask\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "42800441",
      "metadata": {},
      "outputs": [],
      "source": [
        "TRAIN_SET_PATH = \"/opt/shared/datasets/NeoRadiumTDLdataset/train/TDLA\"\n",
        "TEST_SNR_LEVELS = [0, 5, 10, 15, 20, 25, 30]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "7225caa2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 240 files in the dataset\n",
            "Average channel power: 1.0\n"
          ]
        }
      ],
      "source": [
        "file_list = list(Path(TRAIN_SET_PATH).glob(\"*.npy\"))\n",
        "\n",
        "print(\"There are\", len(file_list), \"files in the dataset\")\n",
        "\n",
        "channel_power_list = []\n",
        "for file in file_list:\n",
        "    channel_power_list.append(compute_channel_power(np.load(file).squeeze()))\n",
        "\n",
        "print(\"Average channel power:\", np.array(channel_power_list).mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "e1285e72",
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(Path(TRAIN_SET_PATH, \"metadata.yaml\"), \"r\") as f:\n",
        "    train_metadata = yaml.safe_load(f)\n",
        "\n",
        "large_dataset = TDLDataset(\n",
        "    TRAIN_SET_PATH, \n",
        "    file_size=train_metadata[\"config\"][\"num_channels_per_config\"],\n",
        "    SNRs=TEST_SNR_LEVELS,\n",
        "    return_pilots_only=True)\n",
        "\n",
        "data_loader = DataLoader(large_dataset, batch_size=512, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a39fa3d8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(512, 60, 2)\n",
            "(512, 120, 14)\n",
            "(120, 120)\n"
          ]
        }
      ],
      "source": [
        "for batch in data_loader:\n",
        "    hp_ls, h_true, batch_stats = batch\n",
        "    hp_ls = hp_ls.numpy()\n",
        "    h_true = h_true.numpy()\n",
        "    print(hp_ls.shape)\n",
        "    print(h_true.shape)\n",
        "    pilot_autocorr = compute_autocorrelation(hp_ls)\n",
        "    print(pilot_autocorr.shape)\n",
        "    break    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "854e86ec",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1.1274128+0.0000000e+00j, 1.1944957+0.0000000e+00j,\n",
              "       1.0576942+0.0000000e+00j, 1.1438823+0.0000000e+00j,\n",
              "       1.0601453+0.0000000e+00j, 1.1531299+0.0000000e+00j,\n",
              "       1.0842636+0.0000000e+00j, 1.1956844+0.0000000e+00j,\n",
              "       1.068183 +0.0000000e+00j, 1.1836448+0.0000000e+00j,\n",
              "       1.0921831+0.0000000e+00j, 1.2332484+0.0000000e+00j,\n",
              "       1.072501 +0.0000000e+00j, 1.1754954+0.0000000e+00j,\n",
              "       1.1798823+0.0000000e+00j, 1.2376853+0.0000000e+00j,\n",
              "       1.0406507+1.2106793e-10j, 1.1957436+2.1899077e-10j,\n",
              "       1.0838684-2.6505378e-10j, 1.192205 +3.5072492e-10j,\n",
              "       1.1083679+0.0000000e+00j, 1.1594903+0.0000000e+00j,\n",
              "       1.1049502+0.0000000e+00j, 1.2553414+0.0000000e+00j,\n",
              "       1.1489837+0.0000000e+00j, 1.2509367+0.0000000e+00j,\n",
              "       1.0591795+0.0000000e+00j, 1.1884764+0.0000000e+00j,\n",
              "       1.1305239+0.0000000e+00j, 1.3046973+0.0000000e+00j,\n",
              "       1.088654 +0.0000000e+00j, 1.2595648+0.0000000e+00j,\n",
              "       1.1152133+0.0000000e+00j, 1.203526 +0.0000000e+00j,\n",
              "       1.0544314+0.0000000e+00j, 1.231137 +0.0000000e+00j,\n",
              "       1.1354132+2.1910812e-10j, 1.2476133+5.4191868e-10j,\n",
              "       1.1458682+6.9328421e-10j, 1.1569961+8.6192353e-10j,\n",
              "       1.1095359+0.0000000e+00j, 1.158432 +0.0000000e+00j,\n",
              "       1.0968633+0.0000000e+00j, 1.2598323+0.0000000e+00j,\n",
              "       1.0713184+0.0000000e+00j, 1.2146506+0.0000000e+00j,\n",
              "       1.0920596+0.0000000e+00j, 1.2008731+0.0000000e+00j,\n",
              "       1.043393 +0.0000000e+00j, 1.1674149+0.0000000e+00j,\n",
              "       1.115069 +0.0000000e+00j, 1.2111163+0.0000000e+00j,\n",
              "       1.1050308+0.0000000e+00j, 1.1736637+0.0000000e+00j,\n",
              "       1.1854454+0.0000000e+00j, 1.2098546+0.0000000e+00j,\n",
              "       1.0697994+6.5234351e-10j, 1.1996899+1.0677877e-09j,\n",
              "       1.1222979-7.3046696e-10j, 1.2288392+1.0050547e-09j,\n",
              "       1.0902851+0.0000000e+00j, 1.2320105+0.0000000e+00j,\n",
              "       1.1166569+0.0000000e+00j, 1.2071614+0.0000000e+00j,\n",
              "       1.1220005+0.0000000e+00j, 1.2163988+0.0000000e+00j,\n",
              "       1.1399059+0.0000000e+00j, 1.2278193+0.0000000e+00j,\n",
              "       1.163301 +0.0000000e+00j, 1.262049 +0.0000000e+00j,\n",
              "       1.1787565+0.0000000e+00j, 1.2233549+0.0000000e+00j,\n",
              "       1.170342 +0.0000000e+00j, 1.2423201+0.0000000e+00j,\n",
              "       1.118086 +0.0000000e+00j, 1.3096992+0.0000000e+00j,\n",
              "       1.1731   +1.7030002e-09j, 1.1880888-3.1293762e-10j,\n",
              "       1.2144207-1.2605705e-09j, 1.2157629+1.9722039e-10j,\n",
              "       1.1822066+0.0000000e+00j, 1.2363745+0.0000000e+00j,\n",
              "       1.2404461+0.0000000e+00j, 1.2493072+0.0000000e+00j,\n",
              "       1.19592  +0.0000000e+00j, 1.1898676+0.0000000e+00j,\n",
              "       1.2645259+0.0000000e+00j, 1.240994 +0.0000000e+00j,\n",
              "       1.1967571+0.0000000e+00j, 1.3248856+0.0000000e+00j,\n",
              "       1.1834996+0.0000000e+00j, 1.1709287+0.0000000e+00j,\n",
              "       1.1939878+0.0000000e+00j, 1.2343514+0.0000000e+00j,\n",
              "       1.1870755+0.0000000e+00j, 1.1765286+0.0000000e+00j,\n",
              "       1.1640991+1.4050122e-11j, 1.2447331+1.7772179e-09j,\n",
              "       1.2150071+1.7005128e-09j, 1.2358391+9.0730645e-10j,\n",
              "       1.2164419+0.0000000e+00j, 1.2012966+0.0000000e+00j,\n",
              "       1.2722096+0.0000000e+00j, 1.128869 +0.0000000e+00j,\n",
              "       1.1948237+0.0000000e+00j, 1.2050908+0.0000000e+00j,\n",
              "       1.190928 +0.0000000e+00j, 1.209883 +0.0000000e+00j,\n",
              "       1.2193207+0.0000000e+00j, 1.1762643+0.0000000e+00j,\n",
              "       1.2081902+0.0000000e+00j, 1.2511082+0.0000000e+00j,\n",
              "       1.1912736+0.0000000e+00j, 1.2118254+0.0000000e+00j,\n",
              "       1.2451184+0.0000000e+00j, 1.2644169+0.0000000e+00j,\n",
              "       1.211954 +1.2354018e-09j, 1.170435 -7.8454993e-11j,\n",
              "       1.1743333+1.2945041e-09j, 1.1802909+9.0530916e-10j],\n",
              "      dtype=complex64)"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.diag(pilot_autocorr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba6bdf60",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "lwm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
