{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ba305f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import yaml\n",
        "import pprint\n",
        "from pathlib import Path\n",
        "import random\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42800441",
      "metadata": {},
      "outputs": [],
      "source": [
        "TRAIN_SET_PATH = \"/opt/shared/datasets/NeoRadiumTDLdataset/train/TDLA\"\n",
        "EPOCHS = 10\n",
        "LR = 0.0001\n",
        "LIMIT_DATA_SIZE = 10000\n",
        "TRAIN_SNR_LEVELS = [0, 10, 20]\n",
        "DEVICE = \"cuda:1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "445baf42",
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_mean_and_std(folder_path):\n",
        "    files = list(Path(folder_path).glob(\"*.npy\"))\n",
        "    global_real_mean = 0\n",
        "    global_imag_mean = 0\n",
        "    global_real_std = 0\n",
        "    global_imag_std = 0\n",
        "    for file in files:\n",
        "        file_data = np.load(file)\n",
        "        real_mean = np.mean(file_data.real)\n",
        "        imag_mean = np.mean(file_data.imag)\n",
        "        real_std = np.std(file_data.real)\n",
        "        imag_std = np.std(file_data.imag)\n",
        "        global_real_mean += real_mean\n",
        "        global_imag_mean += imag_mean\n",
        "        global_real_std += real_std\n",
        "        global_imag_std += imag_std\n",
        "    global_real_mean /= len(files)\n",
        "    global_imag_mean /= len(files)\n",
        "\n",
        "    stats = {\n",
        "        \"real_mean\": global_real_mean,\n",
        "        \"imag_mean\": global_imag_mean,\n",
        "        \"real_std\": global_real_std,\n",
        "        \"imag_std\": global_imag_std\n",
        "    }\n",
        "    return stats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f795dadb",
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(Path(TRAIN_SET_PATH, \"metadata.yaml\"), \"r\") as f:\n",
        "    train_metadata = yaml.safe_load(f)\n",
        "print(\"=== TRAIN SET METADATA ===\")\n",
        "pprint.pprint(train_metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d47f8a14",
      "metadata": {},
      "outputs": [],
      "source": [
        "class TDLDataset(Dataset):\n",
        "    def __init__(\n",
        "        self, data_path, *, file_size, normalization_stats=None,return_pilots_only=True, num_subcarriers=120,\n",
        "        num_symbols=14, SNRs=[0, 5, 10, 15, 20, 25, 30],\n",
        "        pilot_symbols=[2, 11], pilot_every_n=2):\n",
        "        \"\"\"\n",
        "        This class loads the data from the folder and returns a dataset of channels.\n",
        "\n",
        "        data_path: path to the folder containing the data\n",
        "        file_size: number of channels per file\n",
        "        return_pilots_only: if True, only the LS channel estimate at pilots are returned\n",
        "            if False, the LS channel estimate is returned as a sparse channel matrix with non-zero \n",
        "            values only at the pilot subcarriers and time instants.\n",
        "        num_subcarriers: number of subcarriers\n",
        "        num_symbols: number of OFDM symbols\n",
        "\n",
        "        SNRs: list of SNR values to randomly sample from when return LS estimates.\n",
        "            AWGN is added to simulate LS estimatation error\n",
        "        pilot_symbols: list of OFDM symbol indices where pilots are placed\n",
        "        pilot_every_n: number of subcarriers between pilot subcarriers\n",
        "        \"\"\"\n",
        "        \n",
        "        self.file_size = int(file_size)\n",
        "        self.normalization_stats = normalization_stats\n",
        "        self.return_pilots_only = return_pilots_only\n",
        "        self.num_subcarriers = num_subcarriers\n",
        "        self.num_symbols = num_symbols\n",
        "        self.SNRs = SNRs\n",
        "        self.pilot_symbols = pilot_symbols\n",
        "        self.pilot_every_n = pilot_every_n\n",
        "\n",
        "        self.file_list = list(Path(data_path).glob(\"*.npy\"))\n",
        "        self.stats = self._get_stats_per_file(self.file_list)\n",
        "        self.data = self._load_data_from_folder(self.file_list, self.normalization_stats)\n",
        "        self.pilot_mask = self._get_pilot_mask()\n",
        "\n",
        "        self.num_pilot_symbols = len(self.pilot_symbols)\n",
        "        self.num_pilot_subcarriers = int(self.pilot_mask.sum()) // self.num_pilot_symbols\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list) * self.file_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_idx = idx // self.file_size\n",
        "        sample_idx = idx % self.file_size\n",
        "        file_path = self.file_list[file_idx]\n",
        "        channels = self.data[file_path]\n",
        "        channel = channels[sample_idx].squeeze().T\n",
        "\n",
        "        SNR = random.choice(self.SNRs)\n",
        "        LS_channel_at_pilots = self._get_LS_estimate_at_pilots(channel, SNR)\n",
        "        stats = self.stats[file_path]\n",
        "        stats[\"SNR\"] = SNR\n",
        "\n",
        "        LS_channel_at_pilots_torch = torch.from_numpy(LS_channel_at_pilots).to(torch.complex64)\n",
        "        channel_torch = torch.from_numpy(channel).to(torch.complex64)\n",
        "        return LS_channel_at_pilots_torch, channel_torch, stats\n",
        "    \n",
        "    @staticmethod\n",
        "    def _load_data_from_folder(file_list, normalization_stats=None):\n",
        "        data = {}\n",
        "        for file_path in file_list:\n",
        "            file_data = np.load(file_path)\n",
        "            if normalization_stats is not None:\n",
        "                normalized_real = (file_data.real - normalization_stats[\"real_mean\"]) / normalization_stats[\"real_std\"]\n",
        "                normalized_imag = (file_data.imag - normalization_stats[\"imag_mean\"]) / normalization_stats[\"imag_std\"]\n",
        "                file_data = normalized_real + 1j * normalized_imag\n",
        "            data[file_path] = file_data\n",
        "        return data\n",
        "\n",
        "    @staticmethod\n",
        "    def _get_stats_per_file(file_list):\n",
        "        stats = {}\n",
        "\n",
        "        for file_path in file_list:\n",
        "            file_name = str(file_path.stem)\n",
        "            file_parts = file_name.split(\"_\")\n",
        "\n",
        "            if file_parts[0] == \"delay\":\n",
        "                delay_spread = int(file_parts[2])  # [delay, spread, y, doppler, x]\n",
        "                doppler_shift = int(file_parts[-1])\n",
        "            elif file_parts[0] == \"doppler\":\n",
        "                doppler_shift = int(file_parts[1])  # [doppler, x, delay, spread, y]\n",
        "                delay_spread = int(file_parts[-1])\n",
        "            else:\n",
        "                raise ValueError(f\"File {file_name} has unexpected format\")\n",
        "            \n",
        "            if file_path not in stats:\n",
        "                stats[file_path] = {\"doppler_shift\": doppler_shift, \"delay_spread\": delay_spread}\n",
        "            else:\n",
        "                raise ValueError(f\"File {file_path} already in stats, but should not be\")\n",
        "            \n",
        "        return stats\n",
        "    \n",
        "    def _get_LS_estimate_at_pilots(self, channel_matrix, SNR):\n",
        "        # unit symbol power and unit channel power --> rx noise var = LS error var\n",
        "        noise_std = np.sqrt(1 / (10**(SNR / 10)))\n",
        "\n",
        "        if self.return_pilots_only:\n",
        "            pilot_mask_bool = self.pilot_mask.astype(bool)\n",
        "            channel_at_pilots = channel_matrix[pilot_mask_bool]\n",
        "            channel_at_pilots = channel_at_pilots.reshape(self.num_pilot_subcarriers, self.num_pilot_symbols)\n",
        "            noise = noise_std * np.random.randn(self.num_pilot_subcarriers, self.num_pilot_symbols)\n",
        "        else:\n",
        "            channel_at_pilots = self.pilot_mask * channel_matrix\n",
        "            noise = noise_std * np.random.randn(self.num_subcarriers, self.num_symbols)\n",
        "            noise = noise * self.pilot_mask\n",
        "        \n",
        "        channel_at_pilots_LS = channel_at_pilots + noise\n",
        "            \n",
        "        return channel_at_pilots_LS\n",
        "\n",
        "    def _get_pilot_mask(self):\n",
        "        pilot_mask = np.zeros((self.num_subcarriers, self.num_symbols))\n",
        "        pilot_mask_subcarrier_indices = np.arange(0, self.num_subcarriers, self.pilot_every_n)\n",
        "        pilot_mask[np.ix_(pilot_mask_subcarrier_indices, self.pilot_symbols)] = 1\n",
        "        return pilot_mask\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2d90776",
      "metadata": {},
      "outputs": [],
      "source": [
        "# simple linear model\n",
        "class LinearModel(nn.Module):\n",
        "    def __init__(self, num_pilot_subcarriers, num_pilot_time_inds, num_subcarriers, num_time_slots):\n",
        "        super(LinearModel, self).__init__()\n",
        "        self.num_pilot_subcarriers = num_pilot_subcarriers\n",
        "        self.num_pilot_time_inds = num_pilot_time_inds\n",
        "        self.num_subcarriers = num_subcarriers\n",
        "        self.num_time_slots = num_time_slots\n",
        "\n",
        "        input_dim = num_pilot_subcarriers * num_pilot_time_inds\n",
        "        output_dim = num_subcarriers * num_time_slots\n",
        "        self.linear = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.dim() == 2:\n",
        "            x = x.unsqueeze(dim=0)  # add batch dimension if not present\n",
        "        x = x.view(x.size(0), -1)\n",
        "        y = self.linear(x)\n",
        "        y = y.view(x.size(0), self.num_subcarriers, self.num_time_slots)\n",
        "        return y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f846c62",
      "metadata": {},
      "outputs": [],
      "source": [
        "normalization_stats = calculate_mean_and_std(TRAIN_SET_PATH)\n",
        "\n",
        "large_dataset = TDLDataset(\n",
        "    TRAIN_SET_PATH, \n",
        "    file_size=train_metadata[\"config\"][\"num_channels_per_config\"],\n",
        "    normalization_stats=normalization_stats,\n",
        "    SNRs=TRAIN_SNR_LEVELS)\n",
        "\n",
        "# sample a subset of the dataset for faster training\n",
        "data_indices = np.random.choice(len(large_dataset), size=LIMIT_DATA_SIZE, replace=False)\n",
        "sampled_dataset = Subset(large_dataset, data_indices)\n",
        "\n",
        "print(\"Dataset size:\", len(sampled_dataset))\n",
        "dataloader = DataLoader(sampled_dataset, batch_size=512, shuffle=True)\n",
        "\n",
        "model = LinearModel(\n",
        "    large_dataset.num_pilot_subcarriers,\n",
        "    large_dataset.num_pilot_symbols,\n",
        "    large_dataset.num_subcarriers,\n",
        "    large_dataset.num_symbols)\n",
        "\n",
        "device = torch.device(DEVICE)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fcd6f39",
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=LR)\n",
        "losses = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    for batch in dataloader:\n",
        "        h_ls, h_true, stats = batch\n",
        "        h_ls = h_ls.to(device)\n",
        "        h_true = h_true.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        h_hat_real = model(h_ls.real)\n",
        "        h_hat_imag = model(h_ls.imag)\n",
        "        loss1 = loss_fn(h_hat_real, h_true.real)\n",
        "        loss2 = loss_fn(h_hat_imag, h_true.imag)\n",
        "        loss = loss1 + loss2\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "        pass\n",
        "    print(f\"Epoch {epoch}, Loss: {loss.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95c3432e",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(losses)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "lwm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
